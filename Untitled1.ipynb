{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4990ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a461e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_decode(rle, height=1024, width=1024, fill_value=1):\n",
    "    component = np.zeros((height, width), np.float32)\n",
    "    component = component.reshape(-1)\n",
    "    rle = np.array([int(s) for s in rle.strip().split(' ')])\n",
    "    rle = rle.reshape(-1, 2)\n",
    "    start = 0\n",
    "    for index, length in rle:\n",
    "        start = start + index\n",
    "        end = start + length\n",
    "        component[start:end] = fill_value\n",
    "        start = end\n",
    "    component = component.reshape(width, height).T\n",
    "    return component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_encode(component):\n",
    "    component = component.T.flatten()\n",
    "    start = np.where(component[1:]>component[:-1])[0] + 1\n",
    "    end = np.where(component[:-1]>component[1:])[0]+1\n",
    "    length = end - start\n",
    "    rle = []\n",
    "    for i in range(len(length)):\n",
    "        if i == 0:\n",
    "            rle.extend([start[i] - end[i-1], length[i]])\n",
    "        else:\n",
    "            rle.extend([start[i] - end[i-1], length[i]])\n",
    "    rle = \" \".join([str(r) for r in rle])\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa77af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    fig,ax = plt.subplots(figsize=(10,6))\n",
    "    ax.imshow(img.permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**image):\n",
    "    images = {k:v.numpy() for k, v in images.items() if isinstance(v, torch.Tensor)}\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    image, mask = images[\"image\"], images[\"mask\"]\n",
    "    plt.imshow(image.transpose(1,2,0), vmin=0, vmax=1)\n",
    "    if mask.max()>0:\n",
    "        plt.imshow(mask.squeeze(0), vmin=0, vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571b668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c78413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40949b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd58184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self):\n",
    "        self.df = rle_df\n",
    "        self.image_base_dir = image_base_dir\n",
    "        self.mask_base_dir = mask_base_dir\n",
    "        self.image_ids = rle_df.ImageId.values\n",
    "        self.augmentation = augmentation\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        image_id = self.image_ids[i]\n",
    "        img_path = os.path.join(self.image_base_dir, image_id+\".png\")\n",
    "        mask_path = os.path.join(self.maske_base_dir, image_id+\".png\")\n",
    "        image = cv2.imread(imag_path, 1)\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = {\"image\": image, \"mask\": mask}\n",
    "            sample = self.augmentation(**sample)\n",
    "            image, mask = sample[\"image\"], sample[\"mask\"]\n",
    "        \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"mask\": mask\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf3423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train transforms\n",
    "TFMS = albu.Compose(\n",
    "    [albu.HorizontalFlip(),\n",
    "    albu.Rotate(10),\n",
    "    albu.Normalize(),\n",
    "    ToTensor()]\n",
    ")\n",
    "\n",
    "# Test transforms\n",
    "TEST_TFMS = albu.Compose([\n",
    "    albu.Normalize(),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ce07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset()\n",
    "val_dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170e091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = train_dataset[1237][\"image\"], train_dataset[1237][\"mask\"]\n",
    "image.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(**train_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56b7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90beda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoSampler(Sampler):\n",
    "    def __init__(self, train_df, positive_perc):\n",
    "        self.train_df = train_df\n",
    "        self.positive_perc = positive_perc\n",
    "        self.positive_idxs = self.train_df.query(\"has_mask==1\").index.values        \n",
    "        self.negative_idxs = self.train_df.query(\"has_mask!=1\").index.values\n",
    "        self.n_positive = len(self.positive_idxs)\n",
    "        self.n_negative = int(self.n_positive * (1 - self.positive_perc) / self.positive_perc)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        negative_sample = np.random.choice(self.negative_idxs, size= self.n_negative)\n",
    "        shuffled = np.random.permutation(np.hstack((negative_sample, self.positive_idxs)))\n",
    "        return iter(shuffled.tolist())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_positive + self.n_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b44f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ed92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, TRAIN_BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, VALID_BATCH_SIZE, shuffle=False, num_worker=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459b96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = next(iter(train_dataloader))[\"image\"], next(iter(train_dataloader))[\"mask\"]\n",
    "images.shape, masks.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "209be594",
   "metadata": {},
   "source": [
    "img_grid = torchvision.utils.make_grid(images[:9], nrow=3, normalize=True)\n",
    "matplotlib_imshow(img_grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
